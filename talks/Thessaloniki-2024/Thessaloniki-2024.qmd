---
title:       Markov chain Monte Carlo and Perfect Simulation
subtitle:    Lecture at Aristotle University of Thessaloniki
date:        15 May 2024
author:     
    - name:           Wilfrid S Kendall
      url:            https://wilfridskendall.github.io/talks/Thessaloniki-2024/Thessaloniki-2024-handout.pdf
      affiliation:    University of Warwick Department of Statistics
      affilation-url: https://www.warwick.ac.uk/statsdept
institute: Department of Statistics, University of Warwick
license:    "CC BY"
---


---
from: markdown+tex_math_single_backslash

format: 
    beamer:
        date-format:     "D MMMM YYYY"
        logo:            image/WarwickStatistics-small.png
        titlegraphic:    image/talk_URL.jpg

        theme:           Boadilla
        mainfont:        "Times New Roman"
        monofont:        "JuliaMono"
        incremental:     true
        link-citations:  true
        citecolor:       blue
        hyperrefoptions:
            - pdfstartview=Fit

        include-in-header:
            - "Thessaloniki-2024.sty"
        nocite: |
            @Rmanual-2010, @MizumotoKagayaZarebskiChowell-2020, @FraserEtAl-2023
---



Introduction   {#sec-introduction}
============

:::: {.columns}

::: {.column}

![`Αριστοτέλης` 384–322 BCE](image/Aristotle_Altemps_Inv8575.jpg){width=2in}

:::

::: {.column}

Aristotle: 

- "Pleasure in the job puts perfection in the work."
- "The more you know, the more you know you don't know."

\pause

\bigskip

\text{ }

\bigskip

Handout available on the web: either use the `QR-code`

\qquad\qquad ![](image/talk_URL.jpg)

:::

::::

or visit <https://wilfridskendall.github.io/talks/Thessaloniki-2024/>.

Sketch of MCMC (I)   {#sec-MCMC-I}
==================
\note{This is a paper from physics, so the senior author comes last in the citation!

\bigskip

The Brown\& May (2004) paper provides an incisive and thoughtful evaluation of Teller's r\^ole 
in American science policy over half a century. 

\bigskip

Teller is said to have appreciated and
repeated the ``monomania" quip -- ascribed by some to Fermi.
\par}
:::: {.columns}

::: {.column}

![Edward Teller (1908-2003)](image/Edward_Teller_in_1958.jpg){width=2in}

:::

::: {.column}

The original Markov chain Monte Carlo method 
(\structure{MCMC}) 
was introduced by @MetropolisRosenbluthRosenbluthTellerTeller-1953.
The senior author was Edward Teller ("father of the H-bomb").

\pause

\bigskip \text{ } \bigskip \text{ } \bigskip  \bigskip \text{ } \medskip

[Fermi once remarked that] Teller was the only monomaniac he knew who had _several_ manias [@BrownMay-2004].
:::

::::



Sketch of MCMC (II): basic Markov chain theory   {#sec-MCMC-II}
==============================================
\note{We begin with a visual introduction to some simple ideas from Markov chain thery
which are fundamental to MCMC and perfect simulation.
\par}
* \structure{Transition probabilities} \(p(a,b)\)  
	![](image/mc1.jpg){height=0.7in}
	\qquad
	![](image/mc2.jpg){height=0.7in}
\note[item]{\structure{Transition rates} in continuous time: 
unified view using exponential distribution.
The transition probabilities \(p(a,b)\) for state \(a\) 
assign proportions of probability to neighbouring states \(b\).}

* \structure{Εquilibrium probabilities} \(\pi(a)\) arise from balance equations;  
    ![](image/mc3.jpg){height=0.7in}  
\note[item]{Solve balance equations: quickly now!}

* \structure{solve} balance equations: equilibrium probabilities defined by the ratio  
	![](image/mc4.jpg){height=1in}

---

* \structure{detailed balance} \(\pi(a) p(a,b)=\pi(b) p(b,a)\), 
	\structure{reversibility};
\note[item]{It's \emph{much} easier if we can arrange balance between individual pairs of states!
Also, curiously, the chain is then \emph{reversible} when in equilibrium.}

![](image/mc5.jpg){height=1in}

![](image/mc6.jpg){height=1in}


---
	
* \structure{Existence of equilibrium:} we need 
\note{Failures for each of these as indicated:
\par}
    - aperiodicity, not  
    ![](image/mc7.jpg){height=0.7in}  
\note[item]{periodicity: chain alternates between blue and red states;}
	- irreducibility, not  
	![](image/mc8.jpg){height=1in}  
\note[item]{reducibility: chain eventually leaves blue states never to return;}
	- recurrence (uniform or geometric recurrence even better), not  
	![](image/mc9.jpg){height=0.7in}
\note[item]{transience: one can show the chain eventually drifts off to left never to return.}


Sketch of MCMC (III)   {#sec-MCMC-III}
====================
The following points are key to designing Markov chains which have the desired target
equilibrium distribution.

* Under detailed balance we can \structure{condition} on specific parts of the state-space by forbidding transitions;  
\note[item]{As long as irreducibility and aperiodicity are preserved, this works fine,
since detailed balance is automatically preserved!}

* We can \structure{modify} any chain, transition probabilities \(p(a,b)\),
to result in a specified target distribution \(\pi(a)\)
\structure{invariant}, by \structure{censoring} each possible transition 
\(a\to b\) with probability \(\alpha(a,b)\in[0,1]\)
such that  
\qquad
\(\alert{\alpha(a,b)}\pi(a) p(a,b)=\alert{\alpha(b,a)}\pi(b) p(b,a)\);
\note[item]{We choose the censoring probability \(\alpha(a,b)\) to force detailed balance to hold!}

* Common choice: \structure{Metropolis-Hastings}  
\qquad\(\alpha(a,b) = \min\{1,(\pi(b) p(b,a)) / (\pi(a) p(a,b))\}\).
\note[item]{There are even some optimality arguments for this, though current research
also investigates other options.}

* If still irreducible aperiodic, then long-term equilibrium is \(\pi(a)\).

* Markov chain Monte Carlo (MCMC), of great statistical importance. 

* But, \alert{physicists always remind us,} physicists got there fifty years earlier!

Sketch of MCMC (IV)   {#sec-MCMC-IV}
====================
Given the \(\pi(a)\), how to \structure{design}
a Markov chain to have this as equilibrium?

(i) \structure{Independence sampler}: propose a draw from a fixed probability distribution,
apply Metropolis-Hastings;
\note[item]{We'll use this.}
(ii) \structure{Random walk Metropolis} or \structure{RWM}: propose a move using a random walk,
apply Metropolis-Hastings;
\note[item]{We'll use this.}
(iii) \structure{Metropolis-adjusted Langevin} or \structure{MALA}:
propose a Gaussian jump shifted using gradient of \(\log\pi\), apply Metropolis-Hastings.\pause

Can mix-and-match! RWM is often favourite: flexible, not too complicated.\pause
\note[item]{We'll mix and match.}

Issues:

(A) \structure{Burn-in}: _How long_ till approximate equilibrium?
(B) \structure{Scaling}: _How big_ should be the RWM jump?\pause

Question (B) is about how to get fast mixing. There is a beautiful and useful theory, but
that is for another day.\pause

Question (A) is what this lecture is all about.

Sketch of MCMC (V)   {#sec-MCMC-V}
===================
* MCMC practicalities: Burn-in: what to do about it?
	- Theory tends to be much too pessimistic. Example: Zanella [-@Zanella-2014; -@Zanella-2015b] developed statistical methods for Anglo-Saxon history: a  _simplified_ model appeared to converge approximately in \(10^5\) steps (about 1 week on compute cluster), _versus_ \(10^9\) steps in theory (around 2 centuries);
	- Is (a) one long run better or (b) many short runs? (Option (b) requires starts of short runs spread "evenly" over the sample space — almost as hard in high dimensions as the original problem!)
	- Diagnostics? (Meta-theorem: for any diagnostic technique there is a chain for which the technique is deceptive!)
	- Conclusion: effective MCMC requires very careful thought about appropriate length of run — think deeply about the problem! 
* Can there ever be a better way?
\note[item]{This, of course, is what this lecture is about!}

Perfect Simulation  {#sec-perfection}
==================
* @ProppWilson-1996a invented exact simulation / Coupling from the Past (CFTP) / perfect simulation;
\note[item]{Jim Propp described the discovery of CFTP as like walking down the street and suddenly noticing
a 50\$ bill lying on the ground.}

* The key ideas of “_classic CFTP_”: 
	- extend simulation _backwards_ through time, 
	- exploit monotonicity by _coupling_ maximal and minimal processes, 
	- seek coalescence;
\note[item]{We will cover these key ideas in a single very specific example.}

* We will study _random-walk-CFTP_, which can in fact be boosted to provide simple image reconstruction using Ising model;
\note[item]{Propp \& Wilson (1996) show how to vary random walk CFTP to get exact samples for 
\structure{critical} Ising model ( (Persi Diaconis: “Like seeing the landscape of Mars for the first time”)). 
Ising model with external field can be used
to model images, hence CFTP can be used for image reconstruction.}

* Everyone immediately suspects the term “perfect simulation” [@Kendall-1998d],
because everyone knows it can't possibly be that good. That's exactly why the term was chosen!
\note[item]{Otherwise some people might imagine “exact simulation” would 
somehow miraculously defeat numerical approximation error :-).}

---

Classic CFTP for a simple random walk (I)
-----------------------------------------
* Consider a simple random walk on \(\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}\).
   - probability of \(+1\) jump is \(p\in(0.1)\), of \(-1\) jump is \(1-p\), **except that** 
   - \(+1\) jump replaced by staying still at state \(9\), **and**
   - \(-1\) jump replaced by staying still at state \(0\).
\note[item]{This is asymmetric simple random walk on the integers, but forbidding any transitions
outside the specified state-space. The result is irreducible \emph{and} aperiodic, so converges
to the discrete uniform distribution (hint: use reversibility to check this!).}

* Conventional MCMC picks a starting point, then runs the simple random walk for long time till approximate equilibrium.
\note[item]{Conventional MCMC is overkill here: we could simulate directly from the equilibrium distribution.}

* How long? One way to _estimate_ this is to run several coupled copies till they meet.
If probability of meeting by time \(T\) is high, then deviation of \(X_T\) from equilibrium is statistically small,
\note[item]{This observation originally formalized by Aldous. Here we use ``synchronous` coupling.}

* Generally \alert{not true} that location at coupling is a draw from equilibrium.
\note[item]{Clearly true in our case: coupling can only occur at \(0\) or \(9\)!}

\only<1-5| handout:0>{\uncover<4-5>{\includegraphics[width=3.5in]{image/basic-rw1.png}}}
\only<6-7| handout:1>{\includegraphics[width=3.5in]{image/basic-rw2.png}}

---

Classic CFTP for a simple random walk (I)
-----------------------------------------
* So now start at a negative time \(-T\), start at top (\(9\)) and bottom (\(0\)), and run to time \(0\). 
\note[item]{Ideally one needs to choose \(T\) neither too small nor
too large. But the result is not sensitive to this.}

* If not coupled, than back-off to time \(-2T\) and repeat.
\note[item]{Very important that one doesn't introduce different jumps for the same time \(-t\)
in this binary back-off! We must \alert{re-use randomness}.}

* We may need to repeat back-off several times.
\note[item]{However the binary back-off procedure means, if \(T\) is too small
then extra work is only ever a factor of \(4\)!}

* If coupled, then return the common value at time \(0\).
\note[item]{Re-use of randomness means there is now no point in continuing: the common value
at time \(0\) will be the same however far we extend into the past with further back-offs.}

* The common value is an exact draw from equilibrium!
\note[item]{Why is the common value an exact draw from equilibrium?
Informally, because one would get the same result however far 
one backed-off: therefore the draw is effectively a draw from time \(-\infty\).
Remarkably, this can easily be converted into a fully rigorous proof!}


\only<1| handout:0>{\includegraphics[width=3.5in]{image/basic-rw3.png}}
\only<2| handout:0>{\includegraphics[width=3.5in]{image/basic-rw4.png}}
\only<3| handout:0>{\includegraphics[width=3.5in]{image/basic-rw5.png}}
\only<4| handout:0>{\includegraphics[width=3.5in]{image/basic-rw6.png}}
\only<5| handout:1>{\includegraphics[width=3.5in]{image/basic-rwCFTP.png}}


A very graphic example  {#sec-graphic-example}
======================
* Many people find _DeadLeaves-CFTP_ helpful [@KendallThoennes-1999];
\note[item]{One of a small class of instances of ``\emph{Occluded CFTP}".
To be clear, this special ``dead leaves" example of CFTP
was probably well-known to the French workers in 
statistics of geology who invented the ``dead leaves" model, well before CFTP had been formally invented.}
* You are walking in a forest in Autumn.
\note[item]{Specifically, the forest at Versailles!}
* You view the leaves falling down on the red soil.
\note[item]{It's an ever-changing pattern. The long-run equilibrium is an important tractable model
in mathematical geomorphology.}

* Change your point of view! Consider a small mammal looking up from a hole in the ground to the blue sky. 
\note[item]{The leaves fall down to form a pattern which is statistically very similar to the pattern viewed from above.}

* Once the hole in the ground is covered, the pattern for the mammal never changes, whereas for the walker
the pattern changes ceaselessly.
\note[item]{That of course is the point for small hibernating mammals.}

* One may deduce, 
[the animal's perceived pattern at coverage is distributed as the long-time equilibrium
for the walker's pattern](https://wilfridskendall.github.io/talks/Thessaloniki-2024/animation/leaf63.gif).
\note[item]{This amounts to noting that in the {i.i.d} case the sequences \(\{X_1, \ldots, X_n\}\) 
and \(\{X_n, \ldots, X_1\}\) have the same distribution (this is the time-reversal component of the CFTP argument here!}

[\uncover<3->{\includegraphics[width=1in]{image/LEAF63-empty1.png}}](animation/leaf63.gif) \uncover<4->{\includegraphics[width=1in]{image/LEAF63-empty2.png}} \qquad \uncover<5->{\includegraphics[width=2in]{image/LEAF63-full.png}}

Some theory about CFTP  {#sec-theory}
======================
* What about cases where monotonicity fails? or there isn’t a sensible “maximal” process? @Kendall-1998d: 
	* cross-couple upper and lower envelope processes, 
	* dominate by amenable “dominating process” (time-reversible, can draw from equilibrium, can couple target processes below dominating process); 
\note[item]{To be computationally effective, the WSK (1998) fixes still require some associated notion of partial order and (perhaps weak) amenability of the dominating process.}
* Theoretical limits:  _in principle_
	- _Classical CFTP_ equivalent to uniform ergodicity [@FossTweedie-1998]. 
	- _Dominated CFTP_ is achievable under geometric ergodicity [@Kendall-2004c]. 
	- It is even possible to carry out Dominated CFTP in some **non**-geometrically ergodicity cases [@ConnorKendall-2007a; _nb_ corrigendum];
\note[item]{Basic ideas: use the notion of regenerative sets (``small sets"),
and (Foster-)Lyapunov arguments. Note that the recipes given for these tend not to be computationally practical:
they simply show the possibility of (possibly computationally infeasible) CFTP.
They are intended as a challenge: when can one find \emph{practical} methods?}
* We can use _Dominated CFTP_ to carry out perfect simulation for stable point processes [@KendallMoeller-2000];
\note[item]{(Locally finite) point processes cannot in general be treated using Classic CFTP, 
because the ``top" pattern would have points \emph{everywhere}.}
* Detailed expositions are given by @Kendall-2005a, @Huber-2015. @Kendall-2014b shows
how to implement CFTP in R.
\note[item]{People who are interested in CFTP from a practical point of view may find it useful to work through WSK (2015).}

Applications to Queues and Epidemics  {#sec-applications}
====================================
\note{The figure refers to a recent crisis 
in which \textbf{both} queues \textbf{and} epidemics played a major part!

\bigskip

We now consider perfect simulation applied to significant probabilistic systems
in queuing theory and in epidemics.
We'll pick up pace here. The primary purpose
is to demonstrate that perfect simulation is more than just a toy technique
for wildly simple cases.

\par}
![An illustration introducing _both_ queues _and_ epidemics!](https://covidposters.github.io/images/queues.png){width=3.5in}

Perfect Queues  {#sec-queues}
==============
 The simplest queuing model (\(M/M/1\): Poisson arrivals, exponential service times, single server) can be analyzed very thoroughly indeed! However:

* Poisson arrivals are not unreasonable, but exponential service times are ludicrous. The \(M/G/1\) case (general service time _for just one server_)
can be analyzed using the “embedded chain” (sample at each departure);
\note[item]{Why are Exponential service times ludicrous? They imply that the fact that
you have been waiting one hour for the previous customer to complete service 
\textbf{has no bearing} on how much longer you still have to wait.
On second thoughts this can be an accurate model in some dire cases! Fortunately,
analysis of the \(M/G/1\) case can use the celebrated Pollaczek-Khintchine formula.}
* Multi-server case: computation of _eg_ waiting-time distribution is out of reach so use simulation [and insights from @KieferWolfowitz-1955];
\note[item]{Kiefer \& Wolfowitz (1955) is a remarkable paper, establishing a fundamental stochastic recursion
for the \emph{KieferWolfowitz workload vector}.}
*  @Sigman-2011 shows how to do CFTP in the "super-stable" case (traffic so low that it could have been handled by just one server), using Dominated CFTP and comparing to a "Processor-Sharing" discipline.
\note[item]{Sigman's result is ingenious and pioneering, but is limited mainly to the case when there is not much
need for an \(M/G/c\) queue with \(c>1\).}

---

* @ConnorKendall-2014 extend @Sigman-2011,
showing how to apply Dominated CFTP to simulate (sub-critical!) queues perfectly; 
now generalized by others to the case of non-Poissonian inter-arrival times. 
(Technical point: pathwise domination needs service times to be assigned in order of commencement of service!) 
The idea is  
    - dominate \(M/G/c\ \operatorname{FCFS}\) (\(\operatorname{FCFS}\) means first come first served)  
    by \(M/G/c\ \operatorname{RA} = [M/G/1\ \operatorname{RA}]^c\)  
    (\(\operatorname{RA}\) means assign to individual servers on arrival);
\note[item]{\(\operatorname{FCFS}\) becomes \(\operatorname{FIFO}\) ("first in first out") for a single server.}
\note[item]{\(M/G/c\ \operatorname{RA} = [M/G/1\ \operatorname{RA}]^c\) is clearly less efficient than \(M/G/c\ \operatorname{FCFS}\); this works pathwise 
so long as we assign service times in order of commencement of service.}
    - use fact that \(M/G/1\ \operatorname{FCFS}\) and \(M/G/1\ \operatorname{PS}\) _workloads_ agree 
     (\(\operatorname{PS}\) means Processor Sharing: pool servers to serve everyone simultaneously)
    and  \(M/G/1\ \operatorname{PS}\) can be simulated backwards in time;  
\note[item]{Calculations for time reversal apply the ideas underlying the Pollaczek-Khintchine formula.}
    - so \([M/G/1\ \operatorname{PS}]^c\) can be used to provide Dominated CFTP.
* @ConnorKendall-2014 describe 
    (a) CFTP coupling when dominating process empties, 
    (b) and a faster CFTP coupling using upper and lower processes 
    starting respectively at dominating process and at empty state. 
\note[item]{Using upper and lower ``sandwiching" is introduced as part of Dominated CFTP in WSK (1998).}

---

Results (I)
-----------
\note{
CFTP algorithms can be tested against special cases where answers \emph{can} be calculated
not just simulated.

\bigskip

Simulations here use \emph{Mathematica} code.
Solid bars indicate theoretical mean number of customers in system; shaded bars show the result of 5000
draws using CFTP.
\par}

Histogram of customer numbers for \(M/M/c\) queue in equilibrium:
arrival rate \(10\), service rate \(2\), and \(10\) servers,
comparing theory 
(available for \(M/M/c\) queue)
with results of @ConnorKendall-2014 algorithm.

![](image/output_10_2_10-juxtaposed_labeled.pdf){width=3in}

---

Results (II)
------------
\note{
Algorithm choice really does make a difference.
In this case, using upper and lower processes results in run-times shorter by a factor of 32,
more than compensating for some increased complexity.

\bigskip

Simulations here use \emph{Mathematica} code.
\par}

Comparison of log-run times for  

(a) CFTP coupling when dominating process empties (solid bars), 
(b) a faster CFTP coupling using upper and lower processes (grey bars).

![](image/output_10_2_10-times-binary_labeled.pdf){width=3in}

---

Results (III)
-------------
\note{
Here, for fun, a detailed look at the last six coordinates of the equilibrium Kiefer-Wolfowitz 
workload vector for a particular \(M/\operatorname{Uniform}(0,1)/c=25\) queue.
("the ordered amounts of residual work in the system for
the \(c\) servers, bearing in mind the \(\operatorname{FCFS}\) queueing discipline").

\bigskip

The coordinates are correlated, and increase monotonically with ``server" (actually, 
Kiefer-Wolfowitz dimension).
Note that the last coordinate
is more skewed, so anticipated to do noticeably more work!

\bigskip

Perfect simulation allows us to place our confidence in these simulation results.

\bigskip

Simulations here use \emph{Mathematica} code.
\par}

Marginal distributions of last six coordinates of the equilibrium Kiefer-Wolfowitz 
workload vector (anticipated work in system) for an \(M/G/c=25\) queue
with Uniform(\(0,1\)) service times and arrival rate \(25\).

::: {layout-nrow=2}

![](image/output_uniform_1_labeled.pdf){width=3in}

![](image/output_uniform_2_labeled.pdf){width=3in}

:::


Perfect Epidemics  {#sec-epidemics}
=================
\note{
Two classical models from mathematical epidemiology.
Even the simple case of deterministic S-I-R permits only \emph{partial} closed-form solution;

\bigskip

The assumption of homogeneous mixing of population greatly simplifies the mathematics \emph{and}
statistics.
Without this assumption one ends up with huge numbers of parameters, which is very bad news statistically speaking.
A lot of research has been done on how to deal with more realistic models!
(For example, [a UK model using 1000000 agents!](https://github.com/BDI-pathogens/OpenABM-Covid19),
Fraser et al, 2023)

\bigskip

However in this work we deal only with homogeneous mixing.
Before running, one must learn to walk!
\par}
**S-I-R deterministic epidemic:** susceptibles $s$, infectives $i$, removals $r$:
$$
\begin{aligned}
s' \quad&=\quad - \alpha \; i \, s \,,
\\
i' \quad&=\quad \left(\alpha \; s - \beta\;\right)\;i \,,
\\
r' \quad&=\quad \beta\; i \,.
\end{aligned}
$$
(Total population $s+i+r=n$​  is constant.)
\pause

**S-I-R stochastic epidemic:** a Markov chain $(S, I, R)$​ with transitions
$$
\begin{aligned}
\textbf{Infection:}& \quad S \to S-1\,, &\; I \to I+1 \qquad&\text{at rate}\qquad \alpha\; I \, S \,,
\\
\textbf{Removal:}& \quad I \to I-1\,, &\; R \to R+1 \qquad&\text{at rate}\qquad \beta\; I  \,.
\end{aligned}
$$

\pause
Both models assume homogeneous mixing.

The first question asked about a new epidemic
=============================================
\note{
I am skipping over very influential early work on this incident,
which particularly focussed on the incubation period
(a time when the subject is infectious, perhaps at time-varying rate, before symptoms appear).
This is pretty much related to $\beta$.


\bigskip

See Mizumoto \emph{et al} (2020) for very early analysis of the \emph{Diamond Princess} outbreak.
\par}
"What is the R-number?"  
\pause
The R-number is $\alpha \; n/\beta$: mean number of new infectives produced per infective at _start_ of epidemic.  
Whittle's threshold theorem: R-number $\gg1$ means positive chance of epidemic infecting significant proportion of the population.
\pause

[*Wikipedia:*](https://en.wikipedia.org/wiki/COVID-19_pandemic_on_Diamond_Princess) 
"The British-registered _Diamond Princess_ was the first cruise ship to have a major `[COVID-19]` outbreak on board, with the ship quarantined at Yokohama from 4 February 2020 for about a month. Of 3711 passengers and crew, around 700 people became infected and 9 people died."  
Evidently $\alpha \; n/\beta \gg 1$ -- as was sadly later confirmed, a sorrow for us all.  
![](image/Diamond_Princess.jpg){width=2in}

Inference on the R-number
=========================
\note{
The ``R-nunber" was the subject of continuing interest throughout the COVID-19 pandemic!
\par}
Important, because the R-number controls severity of epidemic. However:

1. It's \alert{tough}. _Either_ massive assumptions (homogeneous mixing) or far too many parameters;
2. It's \alert{really} \alert{tough}. It's hard to get good information about infection times;
3. It's \alert{especially} \alert{tough} early on. You most need to know the answer when there is hardly any information available (I devised a simplified exercise for a Warwick second-year statistics module to show how tough this is);
4. Markov chain Monte Carlo (MCMC) can be used [@ONeillRoberts-1999] but what about burn-in?
5. Can we use \structure{perfect simulation}?

An easier question
==================
\note{
I learned the phrase ``algorithmic time" from Andrew Stuart.
\par}
1. Suppose we know $n$, $\alpha$, $\beta$​, observe removals, but *don't* observe infections which must be inferred.
2. We need a new chain: namely, the whole S-I-R trajectory evolving in *algorithmic time* 
using varying pattern of potential infections and removals.
3. Visualize $n$ time lines, along which are scattered incidents: 
   * potential removals, activated if time line is infected;
   * potential infections, activated if time line is infected *and* if designated target time line is lowest uninfected time line.
4. Using Poisson point processes of appropriate rates to scatter these incidents, we obtain an S-I-R epidemic.
5. Now let the point patterns evolve _in algorithmic time_, adding and removing incidents according to spatial immigration-death processes.
6. Result is a trajectory-valued chain which has unconditioned S-I-R as equilibrium.


Conditioning on observed removals 
=================================
\note{
Monotonicity is a key concept here. Note however
that we can still sometimes generate perfect simulation algorithms
even when monotonicity does not obtain.

\bigskip
We can also deal with ``unbounded" sample space
using the notion of Dominated CFTP.

\bigskip
The heart of the matter lies in establishing (some variant of) monotonicity.

\bigskip
Additionally. for a complicated algorithm such as this one, it is important
to test the underlying logic by implementing the algorithm in computer code
(which has a way of revealing false hidden assumptions!).
\par}
* The trajectory-valued chain is *reversible*.
* So if we forbid the evolution to get rid of observed removals, and forbid it to introduce new activated removals, then the modified chain has invariant probability measure which conditions on observed pattern of removals. Implications:
  * conditioned removals can change time line (if still activated) but not time of occurrence;
  * removals can be introduced only if they don't activate;
  * sometimes infections cannot be removed (because that would result in losing a conditioned removal).
* More housekeeping details required to define algorithm precisely and make sure reversibility and
mootonicity still work.
* Need to ensure irreducibility (or otherwise equilibrium will depend on starting point).
* Does this produce a feasible algorithm?

Example
=======
\note{
We could vary the assumption concerning the initial and final numbers of infectives while still using essentially the same perfect simulation algorithm!
This assumption amounts to assuming some Bayesian prior knowledge.

\bigskip

Implementation uses \emph{julia},
which combines rapid development, an expressive syntax (very useful for involved algorithms),
and remarkably fast execution using very good ``just in time" compilation techniques.
\par}
* Smallpox outbreak in a closed community of 120 individuals in Abakaliki, Nigeria [@ONeillRoberts-1999; @Bailey-1975, p. 125].
* **Assume**  
    - first observed removal is also the first removal: under a plausible improper prior we can then deduce what is the distribution of infectives $I_0$ at time $0$;
    - all removals are recorded;
    - there are no further removals after the last observed removal.
* Coding in [_julia_](https://julialang.org/) [@BezansonEdelmanKarpinskiShah-2017],  we can construct
[a perfect simulation GIF resulting in a draw from the conditional distribution of pattern of infections](https://wilfridskendall.github.io/talks/Thessaloniki-2024/animation/animation-IS-256.gif).

[\only<1-6>{
\uncover<6>{\includegraphics[height=1.5in]{image/demo-a.pdf}}
}](animation/animation-IS-256.gif)
\only<7| handout:0>{
\includegraphics[height=1.5in]{image/demo-b.pdf}
}
\only<8| handout:0>{
\includegraphics[height=1.5in]{image/demo-c.pdf}
}
\only<9| handout:0>{
\includegraphics[height=1.5in]{image/demo-d.pdf}
}
\only<10| handout:0>{
\includegraphics[height=1.5in]{image/demo-e.pdf}
}

So what?
========
\note{
In effect, perfect simulation supplies a well-behaved stochastic integration mechanism,
reducing an MCMC algorithm to use a technique equivalent to a much more amenable Monte Carlo calculation.
\par}
* You may be wondering, why this emphasis on unobserved infections given fixed $\alpha$ and $\beta$, when what we really want is inference on R-number $\alpha \; n/\beta$ for _unknown_ $\alpha$ and $\beta$?
* Good question. But a re-weighting argument allows us to get (unbiased) estimates based on *different* $\alpha$ and $\beta$. Essentially the perfect simulation provides an exact simulation-based computation which permits us to
integrate out the pattern of unobserved infections. 
* This means we can [**work in progress**, @ConnorKendall-2023]  
    - construct a steepest ascent algorithm 
  (in effect, a variant on a Robbins-Monro stochastic optimization algorithm)
  to find *maximum a posterior* estimates of $\alpha$ and $\beta$;
    - or even, with some computational effort, compute the entire posterior joint density for $\alpha$ and $\beta$!

Conclusion  {#sec-conclusion}
==========
* Are you worried about burn-in issues when doing MCMC. 
Consider whether perfect simulation can be applied!
* CFTP works even for significantly complex and relevant models of real-life phenomena;
* _Of course_ really detailed models will resist perfect simulation: but it can be helpful to compare with a simpler model (especially, using fewer parameters). 
* CFTP is clearly an important tool to be considered by the investigator seeking to 
implement accurate and informative MCMC.
* Thank you for your attention! \alert{QUESTIONS?}

References {.allowframebreaks .t} 
==========

\scriptsize

::: {#refs}
:::

Technical information
=====================

\scriptsize

::: {style="font-size: 15%;"}

| Image         | Attribution                                                                    |              |
| ------------- | ------------------------------------------------------------------------------ | ------------ |
| [Aristotle](https://commons.wikimedia.org/wiki/File:Aristotle_Altemps_Inv8575.jpg) | After Lysippos | _Public domain_ |
|               |                                                                    | via Wikimedia Commons    |
| [Edward Teller](https://commons.wikimedia.org/wiki/File:Edward_Teller_in_1958.jpg) | Lawrence Livermore National Laboratory                       | _[CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0)_    |
|               | restored by w:User:Greg L, Papa Lima Whiskey                       | via Wikimedia Commons    |  
| Perfect Ising                                              | Result of code written by WSK     |              | 
| Classic CFTP and Dead leaves                               | Result of code written by WSK     |              | 
| [Queues](https://covidposters.github.io/images/queues.png) | <https://covidposters.github.io/> |_Open source_ | 
| \(M/M/c\) customers              | Result of code written by Stephen Connor |              | 
| \(M/M/c\) runtimes                      | Result of code written by Stephen Connor |              | 
| \(M/M/c\) loads                   | Result of code written by Stephen Connor |              | 
| [_Diamond Princess_](https://commons.wikimedia.org/wiki/File:Diamond_Princess_(ship,_2004)_-_cropped.jpg) | Alpsdake | _[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)_ |
| Epidemic                                                   | Result of code written by WSK     |              | 
: {tbl-colwidths="[22,50,28]"}
:::

\scriptsize
